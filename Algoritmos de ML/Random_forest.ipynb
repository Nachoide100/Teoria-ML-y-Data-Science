{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d6679f",
   "metadata": {},
   "source": [
    "## ENSEMBLE LEARNING AND RANDOM FOREST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74deda",
   "metadata": {},
   "source": [
    "**1. If you have trained five different models on the exact same training data, and\n",
    "they all achieve 95% precision, is there any chance that you can combine these\n",
    "models to get better results? If so, how? If not, why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a8cbe",
   "metadata": {},
   "source": [
    "Si, es probable que podamos obtener mejores resultados combinando estos modelos utilizando un Voting Classifier. Aunque los modelos independientes tengan una alta precisión, pueden cometer errores diferentes en instancias distintas. Si lo errores de los modelos no están correlacionados entre sí (independientes), la votación permite que los errores individuales se compensen entre sí. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ad6de",
   "metadata": {},
   "source": [
    "**2. What is the difference between hard and soft voting classifiers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a4ae3",
   "metadata": {},
   "source": [
    "La diferencia radica en cómo el ensamble decide la clase final. Mientras que el Hard Voting cuenta los votos de cada modelo individuales y elige la clase que recibió la mayoría de votos, el Soft Voting calcula el promedio de las probabilidades estimadas para cada clase por todos los modelos individuales para luego elegir la clase con la probabilidad promedio más alta. Esto implica que, para usarlo, todos los clasificadores individuales deben ser capaces de estimar probabilidades. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4e1bb",
   "metadata": {},
   "source": [
    "**3. Is it possible to speed up training of a bagging ensemble by distributing it across\n",
    "multiple servers? What about pasting ensembles, boosting ensembles, random\n",
    "forests, or stacking ensembles?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c0cde",
   "metadata": {},
   "source": [
    "La posibilidad de distribuir el entrenamiento depende de si el algoritmo es independiente o secuencial: \n",
    "\n",
    "- Bagging, Pasting y Random Forest: si es posible ya que cada predictor de estos modelos se entrena de forma independiente a los demás utilizando diferentes subconjuntos de datos.\n",
    "- Boosting: no se puede paralelizar fácilmente (o solo de forma limitada) ya que funcionan de forma secuencial, cada predictor se entrena para corregir los errores cometidos por su predecesor, por loq ue no pueden entrenarse al mimsmo tiempo en servidores distintos.\n",
    "- Stacking ensembles: su entrenamiento es mayormente secuencial entre capas. Aunque los modelos dentro de una misma capa si podrían entrenarse en paralelo, el proceso global de pasar de una capa a otra es jerárquico y dependiente (los modelos de la capa 2 necesitan las predicciones de los modelos de la capa 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e357f1",
   "metadata": {},
   "source": [
    "**4. What is the benefit of out-of-bag evaluation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d3185",
   "metadata": {},
   "source": [
    "El benificio principal es que permite evaluar el desempeño de un modelo de bagging sin necesidad de reservar un conjunto de validación por separado. Esto se debe a que, matemáticamente, cada predictori utiliza solo de media el 63% de las instancias de entrenamiento, por lo que el restante son instancias “limpias” que pueden usarse como conjunto de validación, muy útil si la cantidad de datos es escasa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7704a",
   "metadata": {},
   "source": [
    "**5. What makes Extra-Trees more random than regular Random Forests? How can\n",
    "this extra randomness help? Are Extra-Trees slower or faster than regular Ran‐\n",
    "dom Forests?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01add38",
   "metadata": {},
   "source": [
    "Meintras que un Random Forest buscar el mejor umbral posible apra cada característica al dividir un nodo, los Extra-Trees eligen umbrales al azar para cada característica y seleccionann el mejor de esos umbrales aleatorios para realizar la división. Este método supondrá un aumentode las vias pero una reducción de la varianza, asi como un aumento en la velocidad de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a3116",
   "metadata": {},
   "source": [
    "**6. If your AdaBoost ensemble underfits the training data, what hyperparameters\n",
    "should you tweak and how?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08b02b",
   "metadata": {},
   "source": [
    "La aparición del underfitting implica que el modelo es demasiado simple para capturar la estructura de los datos por lo que habrá que aumentar la complejidas del modelo a través de: \n",
    "\n",
    "- Aumento del n_estimators → incrementar el número de predictores secuenciales para que el modelo tenga más oportunidades de corregir los errores acumulados.\n",
    "- Reducir la regularización del estimador base → Por ejemplo si usamos un árbol de decisión, aumentar su complejidas ya sea aumentando su profundidad máxima o reduciendo las restricciones de los leaf nodes.\n",
    "- Aumentar el learning_rate → Ayuda a que cada para de corrección tenga un impacto más fuerte en el resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b756c",
   "metadata": {},
   "source": [
    "**7. If your Gradient Boosting ensemble overfits the training set, should you increase\n",
    "or decrease the learning rate?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb7a84",
   "metadata": {},
   "source": [
    "El learning_rate se encarga de escalar la contribución de cada árbol que se añade al ensamble. Cuando se reduce este valor, cada árbol tiene un impacto menor en el resultado final y es una de las formas más efectivas de regularizar un modelo de Gradiente Boosting y asi evitar el overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8f2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons, fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from scipy.stats import mode\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9a970",
   "metadata": {},
   "source": [
    "**8. Load the MNIST data , and split it into a training set, a\n",
    "validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for val‐\n",
    "idation, and 10,000 for testing).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78570516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Cargar los datos\n",
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "\n",
    "#2. Separación features\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "#3. División de sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=10000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd41231",
   "metadata": {},
   "source": [
    "**Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398561f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Entrenamiento de los modelos\n",
    "# Instancia los modelos\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "ext_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42) \n",
    "\n",
    "# Entrenar los modelos\n",
    "models = [rnd_clf, ext_clf, svm_clf]\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95246422",
   "metadata": {},
   "source": [
    "**Next, try to combine them into an ensemble that outperforms them all on the validation set, using a soft or hard voting classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af51cfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--EVALUACIÓN DE LOS MODELOS SET VALIDACIÓN\n",
      "RandomForestClassifier    -> Accuracy: 0.9692\n",
      "ExtraTreesClassifier      -> Accuracy: 0.9715\n",
      "SVC                       -> Accuracy: 0.9788\n",
      "VotingClassifier (Ensemble) -> Accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "#5. Creación del Voting Classifier\n",
    "named_models = [\n",
    "    (\"random_forest\", rnd_clf),\n",
    "    (\"extra_trees\", ext_clf),\n",
    "    (\"svm\", svm_clf),\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(named_models, voting=\"soft\") # Por defecto es hard voting\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "#6. Evaluación de los modelos en el set de validación\n",
    "models_finals = [rnd_clf, ext_clf, svm_clf, voting_clf]\n",
    "print(\"--EVALUACIÓN DE LOS MODELOS SET VALIDACIÓN\")\n",
    "for model in models_finals:\n",
    "    # Obtenemos el nombre de la clase para identificarlo en el print\n",
    "    name = model.__class__.__name__\n",
    "    if name == \"VotingClassifier\":\n",
    "        name = \"VotingClassifier (Ensemble)\"\n",
    "        \n",
    "    score = model.score(X_val, y_val)\n",
    "    print(f\"{name:25} -> Accuracy: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a5d9e3",
   "metadata": {},
   "source": [
    "**Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1cd035b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUACIÓN DE LOS MODELOS SET DE PRUEBA\n",
      "RandomForestClassifier    -> Accuracy: 0.9645\n",
      "ExtraTreesClassifier      -> Accuracy: 0.9691\n",
      "SVC                       -> Accuracy: 0.9760\n",
      "SOFT VOTING (Ensemble)    -> Accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "print(\"EVALUACIÓN DE LOS MODELOS SET DE PRUEBA\")\n",
    "#7. Predicciones en el test de prueba\n",
    "for clf in models_finals:\n",
    "    name = clf.__class__.__name__\n",
    "    if name == \"VotingClassifier\":\n",
    "        name = \"SOFT VOTING (Ensemble)\"\n",
    "    \n",
    "    # Calculamos el score en el Test Set\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    print(f\"{name:25} -> Accuracy: {test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9318f1",
   "metadata": {},
   "source": [
    "**9. Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image’s class. Train a classifier on this new training set. Congratulations, you have just trained a blender, and together with the classifiers they form a stacking ensemble! Now let’s evaluate the ensemble on the test set. For each image in the test set, make predictions with all your classifiers, then feed the predictions to the blender to get the ensemble’s predictions. How does it compare to the voting classifier you trained earlier?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd769e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del Stacking (Blender): 0.9697\n"
     ]
    }
   ],
   "source": [
    "#1.  Creamos una matriz vacía para las nuevas características\n",
    "X_val_predictions = np.empty((len(X_val), len(models)), dtype=np.float32)\n",
    "\n",
    "#2. Llenamos la matriz con las predicciones de cada modelo\n",
    "for index, model in enumerate(models):\n",
    "    X_val_predictions[:, index] = model.predict(X_val)\n",
    "\n",
    "#3. Instancia y entrenamiento del modelo\n",
    "rnd_forest_blender = RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)\n",
    "rnd_forest_blender.fit(X_val_predictions, y_val)\n",
    "\n",
    "#4. Generar predicciones de la capa base sobre X_test\n",
    "X_test_predictions = np.empty((len(X_test), len(models)), dtype=np.float32)\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    X_test_predictions[:, index] = model.predict(X_test)\n",
    "\n",
    "#5. Predicción final\n",
    "y_pred_final = rnd_forest_blender.predict(X_test_predictions)\n",
    "\n",
    "#6. Evaluación de la precisión\n",
    "print(f\"Precisión del Stacking (Blender): {accuracy_score(y_test, y_pred_final):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
