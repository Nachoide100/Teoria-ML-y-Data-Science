# üß† ML & Data Science Knowledge Base

Bienvenido a mi repositorio de aprendizaje. Aqu√≠ documento las preguntas que surgen de los documentos, libros, papers... sobre Ciencia de Datos y Machine Learning e intento responderlas. **(!! SIN IA !!)**

---

## üó∫Ô∏è Mapa de Navegaci√≥n
*Haz clic en una categor√≠a para explorar los temas.*

| üìÇ [Preguntas Generales](#preguntas-generales) | ü§ñ [Modelos de Predicci√≥n](#modelos-de-prediccion) | üìä [Estad√≠stica y EDA](#estadistica-y-eda) |
| :---: | :---: | :---: |
| Conceptos base y fundamentos | Algoritmos de ML (Cl√°sicos y Avanzados) | An√°lisis y probabilidad |

---

<div id="preguntas-generales"></div>

## üåê 1. Preguntas Generales
*Conceptos transversales que todo Data Scientist debe dominar.*

-  [**Preguntas generales sobre ML:**](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/56a58b8d1059dc221bc5c5f61fdf7890e75fdb47/Conceptos%20Generales/Preguntas_generales.md) ¬øQu√© es el Machine Learning?
-  [**C√≥mo entrenar los modelos de ML:**](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/fae614a93dfddcd9f54b73f68c94567dde716ac7/Algoritmos%20de%20ML/Decision_trees.ipynb) Entendiendo la forma de entrenarlos
-  [**Reducci√≥n de dimensionalidad:**](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/d0a60f25b780e4292627f7cf6d9b8adb8f4aeb11/Conceptos%20Generales/Dimensionality_reduction.ipynb) PCA, kPCA, t-SNE, LLE...




---

<div id="modelos-de-prediccion"></div>

## ü§ñ 2. Modelos de Predicci√≥n
*Anatom√≠a de los algoritmos de Machine Learning.*

## üìà Principales modelos
## [**Support Vector Machines (SVM):**](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/ce58d5ef65fa73ff65a5c653eeb4a01d7e2c82f4/Algoritmos%20de%20ML/SVMs.md) ¬øQu√© son y qu√© podemos hacer con ellas?
## [**Decision Trees:**](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/fae614a93dfddcd9f54b73f68c94567dde716ac7/Algoritmos%20de%20ML/Decision_trees.ipynb) ¬øQu√© son y c√≥mo los utilizamos?
## [**Random Forest (y Ensemble Learning):**](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/43a198ce248b0bd74bff9873062f7918c6b800fa/Algoritmos%20de%20ML/Random_forest.ipynb) Sus caracter√≠sticas y uso.
## [**Aprendizaje No - Supervisado:**](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/dbaa0bd669f6c6d085debb91973edfacda8f3297/Algoritmos%20de%20ML/Unsupervised_learning_techniques.ipynb) Diferentes algoritmos y su aplicaci√≥n.
 ## [**Artificial Neural Networks:**](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/tree/5cd0519654f950f38883032139843d8605efb08b/Algoritmos%20de%20ML/Artificial%20Neural%20Networks) Una visi√≥n general.
  * [Artificial Neural Networks desde 0](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/5cd0519654f950f38883032139843d8605efb08b/Algoritmos%20de%20ML/Artificial%20Neural%20Networks/Artificial%20Neural%20Networks.ipynb)
  * [BackPropagation](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/5cd0519654f950f38883032139843d8605efb08b/Algoritmos%20de%20ML/Artificial%20Neural%20Networks/Backpropagation.ipynb)
  * [Activation Functions y Vanishing Gradient](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/5cd0519654f950f38883032139843d8605efb08b/Algoritmos%20de%20ML/Artificial%20Neural%20Networks/Activation_functions_and_Vanishing.ipynb)
  * [Modelos de regresi√≥n con Keras](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/5cd0519654f950f38883032139843d8605efb08b/Algoritmos%20de%20ML/Artificial%20Neural%20Networks/Regression-with-Keras.ipynb)
  * [Modelos de clasificaci√≥n con Keras](https://github.com/Nachoide100/Teoria-ML-y-Data-Science/blob/5cd0519654f950f38883032139843d8605efb08b/Algoritmos%20de%20ML/Artificial%20Neural%20Networks/Classification-with-Keras.ipynb)
  




---

<div id="estadistica-y-eda"></div>

## üìä 3. Estad√≠stica y EDA
*La base cient√≠fica detr√°s de los datos.*

-  [**Distribuciones de Probabilidad:**](enlace-al-archivo.md) Normal, Binomial y Poisson.
-  [**Teorema del L√≠mite Central:**](enlace-al-archivo.md) La importancia de la campana de Gauss.
-  [**Tratamiento de Outliers:**](enlace-al-archivo.md) ¬øEliminar o transformar?



---

## üõ†Ô∏è C√≥mo usar este repositorio
Cada enlace te llevar√° a un archivo detallado (en formato `.md` o `.ipynb`) donde desarrollo la respuesta, incluyo f√≥rmulas matem√°ticas y, en ocasiones, ejemplos pr√°cticos en Python.

Cualquier pregunta mal respondida o inconclusa no dud√©is en comunic√°rmelo. Un saludo!!

[https://www.linkedin.com/in/jos%C3%A9-ignacio-rubio-194471308/]

